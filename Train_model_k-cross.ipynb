{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO6p1WHLOfIHvk80Ul3Z3L1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"oes5ViI4H6V0"},"outputs":[],"source":["\n","import logging\n","import warnings\n","import os\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n","warnings.filterwarnings('ignore')\n","from PIL import ImageFile\n","import sys\n","import json\n","import datetime\n","import numpy as np\n","import skimage.draw\n","import cv2\n","import matplotlib.pyplot as plt\n","import imgaug\n","\n","# Root directory of the project\n","ROOT_DIR = \"//content//drive//MyDrive//Anum Fatima (MSSE-26) //Code//Codes//Mask RCNN\"\n","from mrcnn.config import Config\n","from mrcnn import model as modellib, utils\n","from mrcnn import parse_args\n","import dataset\n","\n","############################################################\n","#  Args Configurations\n","############################################################\n","\n","args = parse_args.parse_args()\n","# config parameter\n","pretrained_weight = os.path.join(ROOT_DIR, args.weight)\n","dataset_path = os.path.join(ROOT_DIR, args.dataset)\n","logs = os.path.join(ROOT_DIR, \"logs\")\n","\n","if args.continue_train == \"None\":\n","    continue_train = args.continue_train\n","else:\n","    continue_train = os.path.join(ROOT_DIR, args.continue_train)\n","\n","############################################################\n","#  Configurations\n","############################################################\n","\n","class CustomConfig(Config):\n","\n","    NAME = \"custom_dataset\"\n","\n","    IMAGES_PER_GPU = 1\n","\n","    IMAGE_MAX_DIM = 512\n","\n","    NUM_CLASSES = 1 + 5\n","\n","    STEPS_PER_EPOCH = 750\n","\n","    VALIDATION_STEPS = 250\n","\n","    DETECTION_MIN_CONFIDENCE = 0.9\n","\n","    LEARNING_RATE = 0.001\n","\n","    DETECTION_NMS_THRESHOLD = 0.2\n","\n","    TRAIN_ROIS_PER_IMAGE = 200\n","\n","    MAX_GT_INSTANCES = 50\n","\n","    DETECTION_MAX_INSTANCES = 50\n","\n","############################################################\n","#  Training \n","############################################################\n","\n","def train(model):\n","    \"\"\"Train the model.\"\"\"\n","    epoch_count = 0\n","\n","    # training cross-validation with 5 fold\n","    for i in range(5):\n","        # Training dataset.\n","        print(\"Training fold\", i)\n","\n","        dataset_train = dataset.CustomDataset()\n","        dataset_train.load_custom_K_fold(dataset_path, \"train\", i)\n","        dataset_train.prepare()\n","\n","        # Validation dataset\n","        dataset_val = dataset.CustomDataset()\n","        dataset_val.load_custom_K_fold(dataset_path, \"val\", i)\n","        dataset_val.prepare()\n","\n","        \n","        augmentation = imgaug.augmenters.Sometimes(0.5, [\n","                         imgaug.augmenters.Fliplr(0.5),\n","                         imgaug.augmenters.Flipud(0.5)])\n","\n","        model_inference = modellib.MaskRCNN(mode=\"inference\", config=config,model_dir=logs)\n","\n","        mAP_callback = modellib.MeanAveragePrecisionCallback(model, model_inference, dataset_val, \n","                                                        calculate_at_every_X_epoch=25, dataset_limit=500, verbose=1)\n","        # Training - Stage 1\n","        epoch_count += 20\n","        print(\"Training network heads\")\n","        model.train(dataset_train, dataset_val,\n","                    learning_rate=config.LEARNING_RATE *2,\n","                    epochs= epoch_count,\n","                    layers='heads',\n","                    custom_callbacks=[mAP_callback])\n","                    #augmentation=augmentation)\n","\n","        epoch_count += 10\n","        print(\"Fine tune Resnet stage 4 and up\")\n","        model.train(dataset_train, dataset_val,\n","                    learning_rate=config.LEARNING_RATE,\n","                    epochs= epoch_count,\n","                    layers='4+',\n","                    custom_callbacks=[mAP_callback],\n","                    augmentation=augmentation)\n","\n","############################################################\n","#  Training\n","############################################################\n","\n","if __name__ == '__main__':\n","    \n","    print(\"Pre-trained weight: \", pretrained_weight)\n","    print(\"Dataset: \", dataset_path)\n","    print(\"Logs: \", logs)\n","    print(\"Continue Train: \", continue_train)\n","\n","    # Configurations\n","    config = CustomConfig()\n","    config.display()\n","\n","    # Create model\n","    model = modellib.MaskRCNN(mode=\"training\", config=config,\n","                                  model_dir=logs)\n","    \n","    if continue_train.lower() == \"none\":\n","        weights_path = pretrained_weight\n","    else:\n","        weights_path = continue_train\n","\n","    # Load weights\n","    print(\"Loading weights \", weights_path)\n","    if continue_train == \"None\":\n","        # Exclude the last layers because they require a matching\n","        # number of classes\n","        model.load_weights(weights_path, by_name=True, exclude=[\n","            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n","            \"mrcnn_bbox\", \"mrcnn_mask\"])\n","    else:\n","        model.load_weights(weights_path, by_name=True)\n","\n","    train(model)"]}]}