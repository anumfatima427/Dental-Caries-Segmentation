{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJcqFLwvsVDLf9w/muByr1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"uIY67k5PG_sj"},"outputs":[],"source":["import os\n","import cv2\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import skimage\n","import glob\n","import dlib\n","import json\n","from skimage.measure import find_contours\n","\n","# Root directory of the project\n","ROOT_DIR = \"//content//drive//MyDrive//Anum Fatima (MSSE-26) //Code//Codes//Mask RCNN\"\n","\n","# Import Mask RCNN\n","sys.path.append(ROOT_DIR)  # To find local version of the library\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","from mrcnn import parse_args\n","\n","args = parse_args.parse_args()\n","sys.path.append(os.path.join(\"train\"))\n","import dataset\n","import train_model\n","\n","\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","weight_path = args.weight\n","\n","config = training.CustomConfig()\n","dataset_dir = os.path.join(ROOT_DIR, args.dataset)\n","image_path = os.path.join(ROOT_DIR, args.image)\n","\n","# Override the training configurations with a few\n","# changes for inferencing.\n","class InferenceConfig(config.__class__):\n","    # Run detection on one image at a time\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","config = InferenceConfig()\n","config.display()\n","\n","# Device to load the neural network on.\n","# Useful if you're training a model on the same \n","# machine, in which case use CPU and leave the\n","# GPU for training.\n","#DEVICE = \"/gpu:0\"  # /cpu:0 or /gpu:0\n","\n","# Inspect the model in training or inference modes\n","# values: 'inference' or 'training'\n","# TODO: code for 'training' test mode not ready yet\n","\n","\n","# Load validation dataset\n","dataset = dataset.CustomDataset()\n","dataset.load_custom(dataset_dir, \"val\")\n","dataset.prepare()\n","\n","\n","predicted_class = ['BG', 'PrimaryEndodontic', 'PrimaryEndowithSecondaryPerio', 'PrimaryPeriodontal', 'PrimaryPeriowithSecondaryEndo', 'TrueCombined'] #class label\n","\n","# Create model in inference mode\n","#with tf.device(DEVICE):\n","model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n","                              config=config)\n","# Load weights\n","#print(\"Loading weights \", custom_WEIGHTS_PATH)\n","model.load_weights(weight_path, by_name=True)\n","\n","data = {}\n","for filename in sorted(os.listdir(image_path)):\n","\tif filename.endswith(('.JPG','.jpg')):\n","\t\timage = skimage.io.imread(os.path.join(image_path, filename))\n","\t\theight, width = image.shape[:2]\n","\n","\t\tif image.ndim != 3:\n","\t\t\timage = skimage.color.gray2rgb(image)\n","\t\tif image.shape[-1] == 4:\n","\t\t\timage = image[..., :3]\n","\n","\t\tresults = model.detect([image], verbose=1)\n","\t\tr = results[0]\n","\n","\t\t# masks: [height, width, num_instances]\n","\n","\t\tN = len(r['class_ids'])\n","\t\t\n","\t\tsize = os.path.getsize(os.path.join(image_path, filename))\n","\t\tregions = []\n","\t\t\n","\t\tfor i in range(N):\n","\t\t\tif (r['class_ids'][i] <= 4):\n","\t\t\t\t# Extract mask \n","\t\t\t\tmasks = r['masks']\n","\t\t\t\tmask = masks[:, :, i]\n","\n","\t\t\t\t# Create mask polygon\n","\t\t\t\t# Create padding = 1 to ensure proper polygons for masks that touch image edges.\n","\t\t\t\tpadded_mask = np.zeros(\n","\t                (mask.shape[0] + 2, mask.shape[1] + 2), dtype=np.uint8)\n","\t\t\t\tpadded_mask[1:-1, 1:-1] = mask\n","\n","\t\t\t\tcontours = find_contours(padded_mask, 0.5)\n","\t\t\t\tfor verts in contours:\n","\t\t\t\t\t# Subtract the padding and flip (y, x) to (x, y)\n","\t\t\t\t\tverts = np.fliplr(verts) - 1\n","\t\t\t\t# Coordinate of polygon mask\n","\t\t\t\tx = verts[:,0].tolist()\n","\t\t\t\ty = verts[:,1].tolist()\n","\t\t\t\tif (len(x) < 200): continue\n","\t\t\t\t\n","\t\t\t\tlabel  = str(predicted_class[r['class_ids'][i]])\n","\n","\t\t\t\tregions.append({\"shape_attributes\":{\"name\": \"polygon\", \"all_points_x\":x,\"all_points_y\":y},\"region_attributes\":{\"porn\":label}})\n","\n","\t\tid_image = filename + str(size)\n","\t\tdata.update({id_image:{\"filename\":filename,\"size\":size,\"regions\":regions,\"file_attributes\":{}}})\n","\n","# Create annotation file\n","import json\n","with open(image_path + 'via_annotation.json', 'w') as outfile:\n","    json.dump(data, outfile,separators=(',', ':'))\n","print(\"Annotating json file saved as: \", image_path)"]}]}