{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWYhd2BskEmMSeAsCpDv+J"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VLNHhhxMGmMM"},"outputs":[],"source":["import logging\n","import warnings\n","import os\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n","warnings.filterwarnings('ignore')\n","import cv2\n","import sys\n","import random\n","import math\n","import re\n","import time\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","from sklearn.metrics import confusion_matrix\n","import skimage\n","import glob\n","import itertools\n","\n","ROOT_DIR = \"//content//drive//MyDrive//Anum Fatima (MSSE-26) //Code//Codes//Mask RCNN\"\n","\n","sys.path.append(ROOT_DIR)\n","from mrcnn import utils\n","from mrcnn import visualize\n","from mrcnn.visualize import display_images\n","import mrcnn.model as modellib\n","from mrcnn.model import log\n","from mrcnn import parse_args\n","\n","args = parse_args.parse_args()\n","\n","sys.path.append(os.path.join(\"train\"))\n","import dataset\n","import train_model\n","\n","MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n","\n","weight_path = args.weight\n","\n","config = training.CustomConfig()\n","dataset_dir = os.path.join(ROOT_DIR, args.dataset)\n","\n","class InferenceConfig(config.__class__):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","config = InferenceConfig()\n","config.display()\n","\n","model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n","                            config=config)\n","\n","model.load_weights(weight_path, by_name=True)\n","\n","\n","dataset = dataset.CustomDataset()\n","dataset.load_custom(dataset_dir, \"test\")\n","dataset.prepare()\n","print(\"Images: {}\\nClasses: {}\".format(len(dataset.image_ids), dataset.class_names))\n","\n","mAP_pascal = []\n","mAP_coco = []\n","mprecision = []\n","mrecall = []\n","moverlap = []\n","\n","for image_id in dataset.image_ids:\n","    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\n","       modellib.load_image_gt(dataset, config,\n","                              image_id, use_mini_mask=False)\n","    molded_images = np.expand_dims(modellib.mold_image(image, config), 0)\n","    results = model.detect([image], verbose=0)\n","\n","    r = results[0]\n","    index = [x for x in range(len(r['class_ids'])) if r['class_ids'][x] <= 4]\n","\n","    AP_pascal, precision, recall, overlap =utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n","                        r[\"rois\"][index], r[\"class_ids\"][index], r[\"scores\"][index], r['masks'][...,index])\n","    AP_coco = utils.compute_ap_range(gt_bbox, gt_class_id, gt_mask,\n","\t\t                r[\"rois\"][index], r[\"class_ids\"][index], r[\"scores\"][index], r['masks'][...,index])\n","\n","    # if r[\"rois\"].shape[0]:\n","    #     # Precision-Recall curve\n","    #     visualize.plot_precision_recall(AP, precision, recall)\n","    #     # Grid of ground truth objects and their predictions\n","    #     visualize.plot_overlaps(gt_class_id, r['class_ids'], r['scores'], overlap, dataset.class_names)\n","\n","    mAP_pascal.append(AP_pascal)\n","    mAP_coco.append(AP_coco)\n","    mprecision.append(precision)\n","    mrecall.append(recall)\n","    moverlap.append(overlap)\n","\n","\n","print(\"mAP PASCAL\",np.mean(mAP_pascal) * 100,\"%\")\n","print(\"mAP COCO:\",np.mean(mAP_coco) * 100,\"%\")\n","print(\"mean Precision: \", np.mean(mprecision) * 100, \"%\")\n","print(\"mean Recall: \", np.mean(mrecall) * 100, \"%\")\n","print(\"mean Overlaps: \", np.mean(moverlap) * 100, \"%\")"]}]}